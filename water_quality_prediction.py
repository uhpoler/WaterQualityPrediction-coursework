# -*- coding: utf-8 -*-
"""Water Quality Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15EZjRbzxx_YyU89ERo78M9kuWoxO9KNG
"""

import numpy as np
import pandas as pd
from google.colab import drive
drive.mount('/content/drive')

path = "/content/drive/My Drive/data/water_quality_prediction.csv"
df = pd.read_csv(path)
df.head()

features_to_drop = ['Index', 'Color', 'Source','Month','Day','Time of Day','Conductivity','Water Temperature','Air Temperature']
df.drop(columns=features_to_drop, inplace=True)

print(df.columns)

df.describe()

df.info()

# Виведення кількості пропусків у кожному стовпці
missing_values = df.isnull().sum()
print(missing_values)

# Відсоток пропусків у кожному стовпці
missing_percentage = (missing_values / len(df)) * 100
print(missing_percentage)

# Заповнення пропусків медіанними значеннями в решті стовпців
data = df.fillna(df.median())

# Перевірка результатів
print(data.info())

import seaborn as sns
import matplotlib.pyplot as plt

# Визначення стовпців для аналізу
columns_to_analyze = list(data.columns)
columns_to_analyze.remove('Target')  # Вилучаємо таргет для аналізу

# Побудова графіків
for col in columns_to_analyze:
    # Побудова графіків для кожного таргету окремо
    g = sns.FacetGrid(data, col="Target", hue="Target", palette="Set1", height=5)
    g.map(sns.histplot, col, bins=20, kde=True)
    g.set_axis_labels(col, "Frequency")
    g.add_legend()
    plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Виведення графіків для кожного рівня розподілу води з розділенням за значенням таргету
plt.figure(figsize=(40, 30))

# Кількість параметрів
num_params = len(data.columns) - 1  # Мінус 1 для виключення стовпця таргету

# Побудова графіків для кожного параметра
for i, col in enumerate(data.columns[:-1]):  # Цикл за всіма параметрами крім таргету
    plt.subplot(num_params // 3 + 1, 3, i + 1)
    sns.histplot(data=data, x=col, hue='Target', bins=20, kde=True, palette='husl', alpha=0.7)
    plt.title(col)
    plt.xlabel('')
    plt.ylabel('Frequency')

plt.tight_layout()
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split

# Вибір ознак та цільової змінної
X = data.drop(columns='Target')
y = data['Target']

# Розподіл даних на тренувальні та тестові набори у співвідношенні 4:1
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Виведення розмірів тренувального та тестового наборів
print(f'Train set size: {X_train.shape[0]} samples')
print(f'Test set size: {X_test.shape[0]} samples')

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV


# Створюємо параметри для пошуку
param_grid = {'n_neighbors': range(1, 10)}

# Ініціалізуємо KNN класифікатор
knn = KNeighborsClassifier()

# Використовуємо GridSearchCV для пошуку найкращого значення K
grid_search = GridSearchCV(knn, param_grid, cv=5)
grid_search.fit(X_train, y_train)

# Отримуємо найкраще значення K
best_k = grid_search.best_params_['n_neighbors']

print("Найкраще значення K:", best_k)

from sklearn.metrics import accuracy_score
knn = grid_search.best_estimator_
knn.fit(X_train, y_train)

train_prediction_knn = knn.predict(X_train)
test_prediction_knn = knn.predict(X_test)

train_accuracy_knn = accuracy_score(train_prediction_knn, y_train)
test_accuracy_knn = accuracy_score(test_prediction_knn, y_test)

print("[KNN] Training Accuracy:", train_accuracy_knn)
print("[KNN] Test Accuracy:", test_accuracy_knn)

from sklearn.metrics import confusion_matrix, classification_report

# Звіт про класифікацію для тестових даних
class_report = classification_report(y_test, test_prediction_knn)
print("Classification Report:\n", class_report)

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
# Матриця невідповідностей для тестових даних
cm = confusion_matrix(y_test, test_prediction_knn)

# Візуалізація матриці невідповідностей
plt.figure(figsize=(10, 7))
sns.heatmap(cm / np.sum(cm), annot=True, fmt='0.2%', cmap='Reds', cbar=False)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# Обчислення середніх значень кожної ознаки
feature_means = X_train.mean()

# Сортування ознак за середнім значенням
sorted_features = feature_means.sort_values(ascending=False)

# Відображення стовпчикової діаграми важливості ознак
plt.figure(figsize=(10, 7))
plt.bar(sorted_features.index, sorted_features.values, color='skyblue')
plt.title('Feature Importance for KNN')
plt.xlabel('Features')
plt.ylabel('Average Value')
plt.xticks(rotation=45, ha='right')
plt.show()

import numpy as np
from sklearn.ensemble import RandomForestClassifier

rfc = RandomForestClassifier()

rfc.fit(X_train, y_train)
test_prediction_rfc = rfc.predict(X_test)
train_prediction_rfc = rfc.predict(X_train)

test_accuracy_rfc = accuracy_score(y_test, test_prediction_rfc)
train_accuracy_rfc = accuracy_score(y_train, train_prediction_rfc)
print("[RFC] Training Accuracy:", train_accuracy_rfc)
print("[RFC] Test Accuracy:", test_accuracy_rfc)

# Звіт про класифікацію для тестових даних
class_report_rfc = classification_report(y_test, test_prediction_rfc)
print("Classification Report for Random Forest Classifier:\n", class_report_rfc)

from sklearn.metrics import confusion_matrix

# Обчислення матриці невідповідностей для тестових даних
cm_rfc = confusion_matrix(y_test, test_prediction_rfc)

# Візуалізація матриці невідповідностей
plt.figure(figsize=(10, 7))
sns.heatmap(cm_rfc / np.sum(cm_rfc), annot=True, fmt='0.2%', cmap='Blues', cbar=False)
plt.title('Confusion Matrix for Random Forest Classifier')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# Обчислення важливості ознак для Random Forest Classifier
feature_importance = rfc.feature_importances_

# Створення списку назв ознак
features = X.columns

# Створення стовпчикової діаграми з важливістю ознак
plt.figure(figsize=(10, 7))
plt.bar(features, feature_importance, color='skyblue')
plt.title('Feature Importance for Random Forest Classifier')
plt.xlabel('Features')
plt.ylabel('Importance')
plt.xticks(rotation=45, ha='right')
plt.show()

from sklearn.tree import DecisionTreeClassifier
dtc = DecisionTreeClassifier()
dtc.fit(X_train, y_train)

train_predictions_dtc = dtc.predict(X_train)
test_predictions_dtc = dtc.predict(X_test)

train_accuracy_dtc = accuracy_score(y_train, train_predictions_dtc)
test_accuracy_dtc = accuracy_score(y_test, test_predictions_dtc)

print("[DTC] Training Accuracy:", train_accuracy_dtc)
print("[DTC] Test Accuracy:", test_accuracy_dtc)

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Матриця невідповідностей для тестових даних
cm_dtc = confusion_matrix(y_test, test_predictions_dtc)

# Візуалізація матриці невідповідностей
plt.figure(figsize=(10, 7))
sns.heatmap(cm_dtc / np.sum(cm_dtc), annot=True, fmt='0.2%', cmap='Blues', cbar=False)
plt.title('Confusion Matrix for Decision Tree Classifier')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Звіт про класифікацію для тестових даних
class_report_dtc = classification_report(y_test, test_predictions_dtc)
print("Classification Report for Decision Tree Classifier:\n", class_report_dtc)

import numpy as np
import matplotlib.pyplot as plt

# Обчислення важливості ознак для Decision Tree Classifier
feature_importance_dtc = dtc.feature_importances_

# Створення списку назв ознак
features_dtc = X.columns

# Створення стовпчикової діаграми з важливістю ознак
plt.figure(figsize=(10, 7))
plt.bar(features_dtc, feature_importance_dtc, color='skyblue')
plt.title('Feature Importance for Decision Tree Classifier')
plt.xlabel('Features')
plt.ylabel('Importance')
plt.xticks(rotation=45, ha='right')
plt.show()